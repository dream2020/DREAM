# The DREAM Project
![GitHub Logo](/images/dream-eu-logo.png)
## Therapy Room

<p style="text-align: justify;">Vision sensors provide a noncontact, natural, unobstructed way of recording, monitoring and analysing everyday behaviours of people with ASD, e.g. by analysing facial-head movements of ASD individuals<sup>1</sup> as well as eye gaze. These visual cues are important because children with ASD usually have a number of atypical visual behaviours and viewing strategies, such as reduced gaze towards the eyes and preference for the mouth<sup>2</sup>.</p>
<p style="text-align: justify;">Given that placing sensors on children may impede therapy, DREAMwill use RGB-D sensors such as the Microsoft Kinect<sup>®</sup> rather than employing high precision wearable motion tracking devices, together with adaptive action and behaviour analysis software. These will be augmented by techniques for multi-sensor data fusion. Touch sensors and RFID will be optionally considered to capture environment-related information.</p>
<p style="text-align: justify;"></p>


<hr />

&nbsp;

<sup>1 </sup>Madsen, M., El Kaliouby, R., Goodwin, M. &amp; Picard, R. (2008), “Technology for just-in-time in-situ learning of facial affect for persons diagnosed with an autism spectrum disorder”, in: ‘<em>Proceedings of the 10th international ACM SIGACCESS conference on Computers and accessibility’</em>, ACM, 19–26.

<sup>2 </sup>Bird, G., Catmur, C., Silani, G., Frith, C. &amp; Frith, U. (2006), “Attention does not modulate neural responses to social stimuli in autism spectrum disorders”, <em>Neuroimage </em><strong>31</strong>(4), 1614–1624.
