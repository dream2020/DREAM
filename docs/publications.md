## Publications

![Publication](https://dream2020.github.io/DREAM/images/dream-sign2.jpg)

* Senft, E. et al., 2016. SPARC: an efficient way to combine reinforcement learning and supervised autonomy. In FILM Workshop at NIPS’16. Available at: [link](https://dream2020.github.io/DREAM/publications/2016-ES-FILM.pdf).
* Gomez Esteban, P. et al., 2016. A multilayer reactive system for robots interacting with children with autism. In Proceedings of the Fifth International Symposium on New Frontiers in Human-Robot Interaction. Available at: [link](https://cris.cumulus.vub.ac.be/portal/en/publications/a-multilayer-reactive-system-for-robots-interacting-with-children-with-autism(53260d44-6f69-4636-9c26-61f56f643c3d).html).
* Kennedy, J., Baxter, P. & Belpaeme, T., 2015. Head Pose Estimation is an Inadequate Replacement for Eye Gaze in Child-Robot Interaction. In Proceedings of the 10th ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts. pp. 35–36. Available at: [link](https://dream2020.github.io/DREAM/publications/Kennedy2015HeadPose.pdf).
* Baxter, P., Lemaignan, S. & Trafton, J.G., 2016. Cognitive Architectures for Social Human-Robot Interaction (workshop abstract). In Proceedings of the 11th ACM/IEEE International Conference on Human-Robot Interaction. Christchurch, New Zealand.
* Coeckelbergh, M. et al., 2015. A Survey of Expectations About the Role of Robots in Robot-Assisted Therapy for Children with ASD: Ethical Acceptability, Trust, Sociability, Appearance, and Attachment. Science and Engineering Ethics, pp.1–19. Available at: [link](http://dx.doi.org/10.1007/s11948-015-9649-x).
* Yu, H., Ju, Z. & Liu, H., 2014. Image Factorization and Feature Fusion for Enhancing Robot Vision in Human Face Recognition. In Proceedings of IEEE World Congress on Computational Intelligence. Beijing, China: IEEE, pp. 981–986. Available at: [link](http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6889675).
* Tilmans, R. et al., 2015. Social and autonomous confabulation architecture for autism therapy. In Proceedings of the 1st International Conference on Social Robots in Therapy and Education. Available at: [link](http://newfriends2015.org/Proceedings/Contents/Papers/New_Friends_2015_submission_14.pdf).
* Cao, H.-L. et al., 2017. A survey on behavior control architectures for social robots in healthcare interventions. International Journal of Humanoid Robotics. Available at: [link](https://cris.cumulus.vub.ac.be/portal/en/publications/a-survey-on-behavior-control-architectures-for-social-robots-in-healthcare-interventions(188d5d89-e7df-44db-940d-d731726daaa8).html).
* Kennedy, J., Baxter, P. & Belpaeme, T., 2015. Comparing Robot Embodiments in a Guided Discovery Learning Interaction with Children. International Journal of Social Robotics, 7(2), pp.293–308. Available at: [link](https://dream2020.github.io/DREAM/publications/Kennedy2015ComparingRobotEmbodiments.pdf).
* Stahl, B.C. & Coeckelbergh, M., 2016. Ethics of Healthcare Robotics: Towards Responsible Research and Innovation. Robotics and Autonomous Systems, 86, pp.152–161. Available at: [link](https://dream2020.github.io/DREAM/publications/2016/11/1-s2.0-S0921889016305292-main.pdf).
* Ju, Z. et al., 2015. A Novel Approach to Extract Hand Gesture Feature in Depth Images. Multimedia Tools and Applications. Available at: [link](http://link.springer.com/article/10.1007%2Fs11042-015-2609-2).
* Drejing, K., Thill, S. & Hemeren, P., 2015. Engagement: A traceable motivational concept in human-robot interaction. In Affective Computing and Intelligent Interaction (ACII), 2015 International Conference on. pp. 956–961. Available at: [link](http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7344690).
* Senft, E. et al., 2017. Supervised autonomy for online learning in human-robot interaction 2017-03-18, ed. Pattern Recognition Letters. Available at: [link](https://dream2020.github.io/DREAM/publications/2017-ES-PRL.pdf).
* Thill, S. et al., 2012. Robot-assisted therapy for autism spectrum disorders with (partially) autonomous control: Challenges and outlook. Paladyn, 3(4), pp.209–217. Available at: [link](http://dx.doi.org/10.2478/s13230-013-0107-7).
* De Beir , A. et al., 2015. Enhancing Nao expression of emotions using pluggable eyebrows. In Proceedings of the 1st International Conference on Social Robots in Therapy and Education. Windesheim Flevoland. Available at: [link](http://newfriends2015.org/Proceedings/Contents/Papers/New_Friends_2015_submission_10.pdf).
* Ziemke, T., Thill, S. & Vernon, D., 2015. Embodiment is a Double-Edged Sword in Human-Robot Interaction: Ascribed vs. Intrinsic Intentionality. In Proc. Workshop on Cognition: A Bridge between Robotics and Interaction, ACM/IEEE Human Robot Interaction Conference (HRI 2015). Portland, USA, pp. 9–10. Available at: [link](https://dream2020.github.io/DREAM/publications/08/15_Ziemke_Thill_Vernon_HRI.pdf).
* Senft, E. et al., 2015. When is it better to give up? Towards Autonomous Action Selection for Robot Assisted ASD Therapy. In Proceedings of the Tenth Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts. ACM Press, pp. 197–198. Available at: [link](https://dream2020.github.io/DREAM/publications/Senft2015WhenBetterGiveUp.pdf).
* Kennedy, J. et al., 2015. Higher Nonverbal Immediacy Leads to Greater Learning Gains in Child-Robot Tutoring Interactions. In Proceedings of the 7th International Conference on Social Robotics. ICSR ’15. Paris, France: Springer International Publishing, pp. 327–336. Available at: [link](https://dream2020.github.io/DREAM/publications/Kennedy2015HigherNonverbal.pdf).
* Beir, A. De & Vanderboght, B., 2016. Evolutionary Method for Robot Morphology: Case Study of Social Robot Probo. In The Eleventh ACM/IEEE International Conference on Human Robot Interaction. HRI ’16. Christchurch, New Zealand: IEEE Press, pp. 609–610. Available at: [link](http://dl.acm.org/citation.cfm?id=2906831.2907005).
* Peca, A. et al., 2016. Do infants perceive the social robot Keepon as a communicative partner? Infant Behavior and Development, 42, pp.157–167. Available at: [link](http://www.sciencedirect.com/science/article/pii/S0163638315300138).
* Senft, E. et al., 2015. SPARC: Supervised Progressively Autonomous Robot Competencies. In Proceedings of the 7th International Conference on Social Robotics. ICSR ’15. Paris, France: Springer International Publishing, pp. 603–612. Available at: [link](https://dream2020.github.io/DREAM/publications/Senft2015SPARC.pdf).
* Kennedy, J., Baxter, P. & Belpaeme, T., 2015. The Robot Who Tried Too Hard: Social Behaviour of a Robot Tutor Can Negatively Affect Child Learning. In Proceedings of the 10th ACM/IEEE International Conference on Human-Robot Interaction. pp. 67–74. Available at: [link](https://dream2020.github.io/DREAM/publications/Kennedy2015RobotTriedTooHard.pdf).
* Kennedy, J., Baxter, P. & Belpaeme, T., 2017. Nonverbal Immediacy as a Characterisation of Social Behaviour for Human-Robot Interaction. International Journal of Social Robotics, 9(1), pp.109–128. Available at: [link](http://bit.ly/2m1v8Pm).
* Vanderborght, B. et al., 2012. Using the social robot probo as a social story telling agent for children with ASD. Interaction Studies, 13(3), pp.348–372. Available at: [link](http://dx.doi.org/10.1075/is.13.3.02van).
* Kennedy, J., Lemaignan, S. & Belpaeme, T., 2016. The Cautious Attitude of Teachers Towards Social Robots in Schools. In In Proceedings of the Robots 4 Learning Workshop, at RO-MAN 2016. Available at: [link](https://dream2020.github.io/DREAM/publications/Kennedy2016ROMANR4L.pdf).
* Yu, H. & Liu, H., 2014. Regression-Based Facial Expression Optimization. IEEE Transactions on Human-Machine Systems, 44(3), pp.386–394. Available at: [link](http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6798681).
* Simut Vanderborght , R. et al., 2015. Children with autism spectrum disorders make a fruit salad with Probo, the social robot. An interaction study. Journal of Autism and Developmental Disorders, 46(1), pp.113–126. Available at: [link](https://cris.cumulus.vub.ac.be/portal/en/publications/children-with-autism-spectrum-disorders-make-a-fruit-salad-with-probo-the-social-robot-an-interaction-study(e32ef87c-9fdd-4999-b810-c51414d586c5).html).
* Baxter, P. et al., 2016. From Characterising Three Years of HRI to Methodology and Reporting Recommendations. In Proceedings of the 11th ACM/IEEE International Conference on Human-Robot Interaction (alt.HRI). HRI ’16. Christchurch, New Zealand, pp. 391–398. Available at: [link](https://dream2020.github.io/DREAM/publications/Baxter2016AltHRI.pdf).
* de Perre, G. Van et al., 2016. Reaching and pointing gestures calculated by a generic gesture system for social robots. Robotics and Autonomous Systems, 83, pp.32–43. Available at: [link](https://dream2020.github.io/DREAM/publications/Reaching-and-pointing-gestures_final.pdf).
* Baxter, P. et al., 2016. The Effect of Repeating Tasks on Performance Levels in Mediated Child-Robot Interactions. In In Proceedings of the Robots 4 Learning Workshop, at RO-MAN 2016. Available at: [link](https://dream2020.github.io/DREAM/publications/Baxter2016ROMANR4L.pdf).
* Baxter, P., 2016. Memory-centred cognitive architectures for robots interacting socially with humans. In Proceedings of the 2nd Workshop on Cognitive Architecture for Social Human-Robot Interaction, at HRI’16. Christchurch, New Zealand. Available at: [link](https://dream2020.github.io/DREAM/publications/Baxter2016Memory.pdf).
* Pop, C.A. et al., 2013. Can the Social Robot Probo help Children with Autism to Identify Situation-based Emotions? International Journal of Humanoid Robotics, 10(3). Available at: [link](http://www.worldscientific.com/doi/abs/10.1142/S0219843613500254).
* Gao, D. et al., 2015. Real time Object Tracking Via a Mixture Model. In 24th IEEE International Symposium on Robot and Human Interactive Communication. Kobe, Japan: IEEE, pp. 112–116. Available at: [link](http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7333701).
* Thill, S. & Vernon, D., 2015. How to design emergent models of cognition for application-driven artificial agents. In Proc. Neural Computation Psychology Workshop (in press). Available at: [link](https://dream2020.github.io/DREAM/publications/15_Thill_Vernon_NCPW.pdf).
* Senft, E. et al., 2017. Leveraging Human Inputs in Interactive Machine Learning for Human Robot Interaction. In Proceedings of the 12th ACM/IEEE International Conference on Human-Robot Interaction. HRI ’17. Available at: [link](https://dream2020.github.io/DREAM/publications/2017-ES-HRI_LBR.pdf).
* Zhang, S. et al., 2015. Automatic Reconstruction of Dense 3D Face Point Cloud with A Single Depth Image. In Proceedings of the 2015 IEEE International Conference on Systems, Man, and Cybernetics. Hong Kong, China. Available at: [link](http://eprints.port.ac.uk/18857/).
* Zhang, S. et al., 2015. Combining Kinect and PnP for Camera Pose Estimation. In In: Proceedings of the 8th International Conference on Human System Interaction. Warsaw,Poland: IEEE, pp. 357–361. Available at: [link](http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7170693).
* Cao, H.-L. et al., 2016. A platform-independent robot control architecture for multiple therapeutic scenarios. In Proceedings of the Fifth International Symposium on New Frontiers in Human-Robot Interaction. Available at: [link](https://cris.cumulus.vub.ac.be/portal/en/publications/toward-a-platformindependent-social-behavior-architecture-for-multiple-therapeutic-scenarios(2ff3b2d9-4092-4232-bf8b-a4c700ab3111).html).
* Wang, Y. et al., 2015. Dynamic Facial Expression Recognition Using Local Patch and LBP-TOP. In Proceedings of the 8th International Conference on Human System Interaction. Warsaw ,Poland: IEEE, pp. 362–367. Available at: [link](https://dx.doi.org/10.1109/HSI.2015.7170694).
* Kennedy, J. et al., 2017. Child Speech Recognition in Human-Robot Interaction: Evaluations and Recommendations. In Proceedings of the 12th ACM/IEEE International Conference on Human-Robot Interaction. Vienna, Austria. Available at: [link](https://dream2020.github.io/DREAM/publications/Kennedy2017HRIFull.pdf).
* Kennedy, J., Baxter, P. & Belpaeme, T., 2015. Can Less be More? The Impact of Robot Social Behaviour on Human Learning. In Proceedings of the 4th International Symposium on New Frontiers in HRI at AISB 2015. Canterbury, UK. Available at: [link](http://www.cs.kent.ac.uk/events/2015/AISB2015/proceedings/hri/5-Kennedy-canlessbe.pdf).
* Beir, A. De et al., 2016. Enhancing emotional facial expressiveness on NAO. International Journal of Social Robotics, 8(4), pp.513–521. Available at: [link](https://link.springer.com/article/10.1007/s12369-016-0363-x).
* Hoang-Long, C. et al., 2017. An End-User Interface to Generate Homeostatic Behavior for NAO Robot in Robot-Assisted Social Therapies. In I. Rojas, G. Joya, & A. Catala, eds. Cham: Springer International Publishing, pp. 609–619. Available at: [link](http://dx.doi.org/10.1007/978-3-319-59147-6_52).
* Baxter, P. et al., 2015. Touchscreen-Mediated Child-Robot Interactions Applied to ASD Therapy. In Proceedings of the 1st International Conference on Social Robots in Therapy and Education. Almere, Netherlands. Available at: [link](https://dream2020.github.io/DREAM/publications/Baxter2015TouchscreenMediated.pdf).
* Cai, H. et al., 2015. Visual Focus of Attention Estimation Using Eye Center Localization. Systems Journal,IEEE, PP(99), pp.1–6. Available at: [link](http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7151779&url=http%3A%2F%2Fieeexplore.ieee.org%2Fiel7%2F4267003%2F4357939%2F07151779.pdf%3Farnumber%3D7151779)%3Farnumber%3D7151779.
* Kennedy, J. et al., 2016. Heart vs Hard Drive: Children Learn More From a Human Tutor Than a Social Robot. In Proceedings of the 11th ACM/IEEE International Conference on Human-Robot Interaction. HRI ’16. Christchurch, New Zealand, pp. 451–452. Available at: [link](https://dream2020.github.io/DREAM/publications/Kennedy2016HeartvsHard.pdf).
* Cao, H.-L. et al., 2015. Toward a platform-independent social behavior architecture for multiple therapeutic scenarios. In Proceedings of the 1st International Conference on Social Robots in Therapy and Education. Available at: [link](http://newfriends2015.org/Proceedings/Contents/Papers/New_Friends_2015_submission_16.pdf).
* Pop, C.A. et al., 2013. Social Robots vs. Computer Display: Does the Way Social Stories are Delivered Make a Difference for Their Effectiveness on ASD Children? Journal of Educational Computing Research, 49(3), pp.381–401. Available at: [link](http://jec.sagepub.com/content/49/3/381).
* de Perre, G. Van et al., 2017. Generic method for generating blended gestures and affective functional behaviors for social robots. Autonomous Robots, pp.1–12. Available at: [link](https://link.springer.com/article/10.1007/s10514-017-9650-0).
* Pop, C.A. et al., 2014. Enhancing play skills, engagement and social skills in a play task in ASD children by using robot-based interventions. Interaction Studies, 15(2), pp.71–91. Available at: [link](http://dx.doi.org/10.1075/is.15.2.14pop).
* Van de Perre , G. et al., 2015. Development of a generic method to generate upper-body emotional expressions for different social robots. Advanced Robotics, 29(9), pp.597–609. Available at: [link](http://www.tandfonline.com/doi/abs/10.1080/01691864.2015.1031697#.VcisIPmqpBc).
* Peca, A. et al., 2014. How do typically developing children and children with autism perceive different social robots? Computers in Human Behavior, 41, pp.268–277. Available at: [link](http://www.sciencedirect.com/science/article/pii/S0747563214004932).
* Cao, H.-L. et al., 2014. Enhancing My Keepon Robot: A Simple and Low-Cost Solution for Robot Platform in Human-Robot Interaction Studies. In Proceedings of the 23rd IEEE International Symposium on Robot and Human Interactive Communication. Edinburgh, UK, pp. 555–560. Available at: [link](http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&amp;arnumber=6926311).
* Hoang-Long, C. et al., 2017. A Collaborative Homeostatic-Based Behavior Controller for Social Robots in Human--Robot Interaction Experiments. International Journal of Social Robotics. Available at: [link](http://dx.doi.org/10.1007/s12369-017-0405-z).
* Senft, E. et al., 2016. Providing a Robot with Learning Abilities Improves its Perception by Users. In Proceedings of the 11th ACM/IEEE International Conference on Human-Robot Interaction. HRI ’16. Christchurch, New Zealand, pp. 513–514. Available at: [link](https://dream2020.github.io/DREAM/publications/Senft2016Providing.pdf).
* Beckerle, P. et al., 2016. Human body schema exploration: Analyzing design requirements of Robotic Hand and Leg Illusions. In Robot and Human Interactive Communication (RO-MAN), 2016 25th IEEE International Symposium on. pp. 763–768. Available at: [link](http://ieeexplore.ieee.org/abstract/document/7745205/).
* Zhou, X. et al., 2015. Tracking Multiple Video Targets with an Improved GM-PHD Tracker. Sensors, 15(12), p.29794. Available at: [link](http://www.mdpi.com/1424-8220/15/12/29794).
* Kennedy, J. et al., 2016. Social Robot Tutoring for Child Second Language Learning. In Proceedings of the 11th ACM/IEEE International Conference on Human-Robot Interaction. HRI ’16. Christchurch, New Zealand, pp. 231–238. Available at: [link](https://dream2020.github.io/DREAM/publications/Kennedy2016SocialRobot.pdf).
* Cao, H.-L. et al., 2015. Toward a platform-independent social behavior architecture for multiple therapeutic scenarios. In Proceedings of the 1st International Conference on Social Robots in Therapy and Education. Windesheim Flevoland. Available at: [link](https://cris.cumulus.vub.ac.be/portal/en/publications/toward-a-platformindependent-social-behavior-architecture-for-multiple-therapeutic-scenarios(2ff3b2d9-4092-4232-bf8b-a4c700ab3111)/export.html).
* Peca, A. et al., 2015. Are children with ASD more prone to test the intentions of the Robonova robot compared to a human? International Journal of Social Robotics, 7(5), pp.629–639. Available at: [link](https://cris.cumulus.vub.ac.be/portal/en/publications/are-children-with-asd-more-prone-to-test-the-intentions-of-the-robonova-robot-compared-to-a-human(628967bf-bcbe-4fdb-b5c7-b8d1ccc0e8c3).html).
* Wills, P. et al., 2016. Socially Contingent Humanoid Robot Head Behaviour Results in Increased Charity Donations. In Proceedings of the 11th ACM/IEEE International Conference on Human-Robot Interaction. HRI ’16. Christchurch, New Zealand, pp. 533–534. Available at: [link](https://dream2020.github.io/DREAM/publications/Wills2016SociallyContingent.pdf).
* Senft, E., Baxter, P. & Belpaeme, T., 2015. Human-Guided Learning of Social Action Selection for Robot-Assisted Therapy H. Cuayáhuitl et al., eds. Journal of Machine Learning Research, 43, pp.15–20. Available at: [link](http://jmlr.org/proceedings/papers/v43/senft15.pdf).
* Costescu, C.A., Vanderborght, B. & David, D., 2014. The effects of robot-enhanced psychotherapy. A meta-analysis. Review of General Psychology, 18(2), pp.127–136. Available at: [link](https://asknao.aldebaran.com/sites/default/files/publications/review_of_general_psychology_costescu_1.pdf).
* Lemaignan, S. et al., 2016. Towards “Machine-Learnable” Child-Robot Interactions: the PInSoRo Dataset. In Proceedings of the Long-Term Child-Robot Interaction Workshop, at RO-MAN 2016. Available at: [link](https://dream2020.github.io/DREAM/publications/Lemaignan2016ROMANWorkshop.pdf).
* Vernon, D., Thill, S. & Ziemke, T., 2015. The Role of Intention in Cognitive Robotics. In A. Esposito & L. C. Jain, eds. Socially Believable Behaving Systems - The Quest for Equipping Machines with Human-Level Automaton Intelligence. Springer. Available at: [link](https://dream2020.github.io/DREAM/publications/15_Vernon_Thill_Ziemke_SBBS1.pdf).
* Cai, H. et al., 2015. Conlution-Based Means of Gradient for Fast Eye Centre Localization. In 7th International Conference on Machine Learning and Cybernetics. Guangzhou,China.
* Kennedy, J., Baxter, P. & Belpaeme, T., 2017. The Impact of Robot Tutor Nonverbal Social Behaviour on Child Learning. Frontiers in ICT, 4(6). Available at: [link](http://journal.frontiersin.org/article/10.3389/fict.2017.00006/abstract).
* Vernon, D. et al., 2015. An Architecture-oriented Approach to System Integration in Collaborative Robotics Research Projects — An Experience Report. Journal of Software Engineering for Robotics, 6(1), pp.15–32. Available at: [link](https://dream2020.github.io/DREAM/publications/2016/02/15_Vernon_et_al_JOSER.pdf).
* Tapus, A. et al., 2012. Children with autism social engagement in interaction with Nao, an imitative robot A series of single case experiments. Interaction Studies, 13(3), pp.315–347. Available at: [link](http://dx.doi.org/10.1075/is.13.3.01tap).
* Cai, H. et al., 2015. Gaze Estimation Driven Solution for Interacting Children with ASD. In 26th 2015 International Symposium on Micro-NanoMechatronics and Human Science. Nagoya, Japan.
* Cao, H.-L. et al., 2015. Probolino: A Portable low-cost social device for home-based autism therapy. In A. Tapus et al., eds. Proceedings of the 7th International Conference on Social Robotics. Lecture Notes in Computer Science. Springer, pp. 93–102. Available at: [link](https://cris.cumulus.vub.ac.be/portal/en/publications/probolino-a-portable-lowcost-social-device-for-homebased-autism-therapy(0ea075a7-6e41-4490-b3ba-2f0ca90613bf).html).
* Yu, H. & Liu, H., 2014. Linear Regression for Head Pose Analysis. In Proceedings of IEEE World Congress on Computational Intelligence. Beijing ,China: IEEE, pp. 987–992. Available at: [link](http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6889676).
* Baxter, P. et al., 2015. The wider supportive role of social robots in the classroom for teachers. In Proceedings of the 1st International Workshop on Educational Robotics, at ICSR 2015. Paris, France. Available at: [link](https://dream2020.github.io/DREAM/publications/Baxter2015WiderRobotsInClassroom.pdf).
* Simut Vanderborght, R. et al., 2016. Are social robots social enough for preschoolers with autism spectrum disorder? In XI Autism Europe International Conference. Available at: [link](https://cris.cumulus.vub.ac.be/portal/en/publications/are-social-robots-social-enough-for-preschoolers-with-autism-spectrum-disorder(dafb1027-148e-4322-912d-1baf93c0d2ee).html).
* Esteban, P.G. et al., 2017. How to build a supervised autonomous system for robot-enhanced therapy for children with autism spectrum disorder. Paladyn: journal of behavioral robotics, pp.18–38. Available at: [link](https://dream2020.github.io/DREAM/publications/Paladyn-Journal-of-Behavioral-Robotics-How-to-Build-a-Supervised-Autonomous-System-for-Robot-Enhanced-Therapy-for-Children-with-Autism-Spectrum-Disorder.pdf).
* Cao, H.-L. et al., 2014. ROBEE: A homeostatic-based social behavior controller for robots in Human-Robot Interaction experiments. In Proceedings of the 2014 IEEE International Conference on Robotics and Biomimetics. Bali, Indonesia: IEEE, pp. 516–521. Available at: [link](http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7090383).
* Peca, A. et al., 2016. A scale measuring ethical acceptability of Robot Enhanced Therapy for children with Autism Spectrum Disorders. IEEE Technology And Society Magazine. Available at: [link](https://cris.cumulus.vub.ac.be/portal/en/publications/a-scale-measuring-ethical-acceptability-of-robot-enhanced-therapy-for-children-with-autism-spectrum-disorders(7bea3130-8aaf-4ecb-a4f7-5ba37e701390)/export.html).
* Kennedy, J. et al., 2015. Using Immediacy to Characterise Robot Social Behaviour in Child-Robot Interactions. In Proceedings of the 1st Workshop on Evaluating Child-Robot Interaction, at ICSR 2015. Paris, France. Available at: [link](https://dream2020.github.io/DREAM/publications/Kennedy2015ImmediacyCharacterise.pdf).
* Ju, Z. et al., 2015. An Integrative Framework of Human Hand Gesture Segmentation for Human–Robot Interaction. Systems Journal, IEEE, PP(99), pp.1–11. Available at: [link](http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7244188).
* David, D., Matu, S. & David, O., 2014. Robot-Based Psychotherapy: Concepts Development, State of the Art, and New Directions. International Journal of Cognitive Therapy, 7(2), pp.192–210. Available at: [link](http://guilfordjournals.com/doi/abs/10.1521/ijct.2014.7.2.192).
* Vernon, D., Beetz, M. & Sandini, G., 2015. Prospection in cognition: the case for joint episodic-procedural memory in cognitive robotics. Frontiers in Robotics and AI, 2(19), pp.1–14. Available at: [link](http://journal.frontiersin.org/article/10.3389/frobt.2015.00019/abstract).
* Baxter, P. & Belpaeme, T., 2016. A cautionary note on personality (extroversion) assessments in child-robot interaction studies. In Proceedings of the 2nd Workshop on Evaluating Child-Robot Interaction, at HRI’16. Christchurch, New Zealand. Available at: [link](https://dream2020.github.io/DREAM/publications/Baxter2016Cautionary.pdf).
